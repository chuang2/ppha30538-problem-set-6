---
title: "Problem Set 6 - Waze Shiny Dashboard"
author: "Peter Ganong, Maggie Shi, and Andre Oviedo"
date: today
format: 
  pdf:
    include-in-header: 
       text: |
         \usepackage{fvextra}
         \DefineVerbatimEnvironment{Highlighting}{Verbatim}{breaklines,commandchars=\\\{\}}
include-before-body:
  text: |
    \RecustomVerbatimEnvironment{verbatim}{Verbatim}{
      showspaces = false,
      showtabs = false,
      breaksymbolleft={},
      breaklines
    }
---
1. **ps6:** Due Sat 23rd at 5:00PM Central. Worth 100 points (80 points from questions, 10 points for correct submission and 10 points for code style) + 10 extra credit. 

We use (`*`) to indicate a problem that we think might be time consuming. 

# Steps to submit (10 points on PS6) {-}

1. "This submission is my work alone and complies with the 30538 integrity
policy." Add your initials to indicate your agreement: \*\*\_\_\*\*
2. "I have uploaded the names of anyone I worked with on the problem set **[here](https://docs.google.com/forms/d/185usrCREQaUbvAXpWhChkjghdGgmAZXA3lPWpXLLsts/edit)**"  \*\*\_\_\*\* (2 point)
3. Late coins used this pset: \*\*\_\_\*\* Late coins left after submission: \*\*\_\_\*\*

4. Before starting the problem set, make sure to read and agree to the terms of data usage for the Waze data [here](https://canvas.uchicago.edu/courses/59054/quizzes/130617).

5. Knit your `ps6.qmd` as a pdf document and name it `ps6.pdf`.
6. Push your `ps6.qmd`, `ps6.pdf`, `requirements.txt`, and all created folders (we will create three Shiny apps so you will have at least three additional folders) to your Github repo (5 points). It is fine to use Github Desktop.
7. Submit `ps6.pdf` and also link your Github repo via Gradescope (5 points)
8. Tag your submission in Gradescope. For the Code Style part (10 points) please tag the whole correspondingsection for the code style rubric.

*Notes: see the [Quarto documentation (link)](https://quarto.org/docs/authoring/figures.html) for directions on inserting images into your knitted document.*

*IMPORTANT: For the App portion of the PS, in case you can not arrive to the expected functional dashboard we will need to take a look at your `app.py` file. You can use the following code chunk template to "import" and print the content of that file. Please, don't forget to also tag the corresponding code chunk as part of your submission!*

```{python}
#| echo: true
#| eval: false

def print_file_contents(file_path):
    """Print contents of a file."""
    try:
        with open(file_path, 'r') as f:
            content = f.read()
            print("```python")
            print(content)
            print("```")
    except FileNotFoundError:
        print("```python")
        print(f"Error: File '{file_path}' not found")
        print("```")
    except Exception as e:
        print("```python") 
        print(f"Error reading file: {e}")
        print("```")

print_file_contents("./top_alerts_map_byhour/app.py") # Change accordingly
```

```{python} 
#| echo: false

# Import required packages.
import pandas as pd
import altair as alt 
import pandas as pd
from datetime import date
import numpy as np
alt.data_transformers.disable_max_rows() 

import json
```

# Background {-}

## Data Download and Exploration (20 points){-} 

1. 

```{python}
import zipfile

zipfile_path = "/Users/charleshuang/Documents/GitHub/real_merge_example/ppha30538-problem-set-6/waze_data.zip"

extract_to = "/Users/charleshuang/Documents/GitHub/real_merge_example/ppha30538-problem-set-6"

with zipfile.ZipFile(zipfile_path, 'r') as zip_ref:
    zip_ref.extractall(extract_to)

print(f"Files have been extracted to {extract_to}")


```

Loading waze sample data into a df:

```{python}
wz_sample = pd.read_csv("waze_data_sample.csv", index_col=None)

wz_sample.head()
wz_sample = wz_sample.drop(columns=["Unnamed: 0"])

#Variable names:

wz_vars = wz_sample.columns
print(wz_vars)

#using altair syntax
wz_data_types = "Nominal", "Quantitative", "Quantitative", "Nominal", "Nominal", "Nominal", "Nominal", "Nominal", "Nominal", "Quantitative", "Quantitative", "Ordinal", "N/A", "N/A", "N/A"

```

We can create a table of variable names and data types below:
```{python}
vars_and_types = pd.DataFrame({
  'Variable Names': wz_vars,
  'Variable Types': wz_data_types
})

print(vars_and_types)
```

2. 

```{python}

wz_full = pd.read_csv("waze_data.csv", index_col=None)

wz_full.head()

#Create a stacked bar chart where x axis is each variable and it shows proportion of missing vs. non missing values
#To do this, we need to create a function and then apply() it to each variable in the df

def calc_missing(column):
    missing_no = column.isna().sum()
    non_missing_no = len(column) - missing_no
    return pd.Series({'Missing': missing_no, 'Non-missing': non_missing_no})

missing_counts = wz_full.apply(calc_missing)
print(missing_counts)

#This needs to be converted from wide to long so that each variable (city, confidence, etc.) is in one col. We can do this using melt

missing_counts_long = missing_counts.reset_index().melt(
    id_vars='index',
    var_name='Variable Name',
    value_name='Count of Observations'
)
print(missing_counts_long)


wz_missing_stacked = alt.Chart(missing_counts_long).mark_bar().encode(
  x='Variable Name',
  y='Count of Observations',
  color='index'
)

wz_missing_stacked

```
We can see that nThumbsUp, street, and subtype have missing values, with nThumbsUp having the largest proportion of missing values.

3. Print the unique values for columns type and subtype:

```{python}
#We need to group the data by type, and then list the subtypes for each type

wz_group_by_type = wz_full.groupby('type')
pd.set_option('display.max_colwidth', None)

full_subtypes = (wz_group_by_type['subtype'].unique())
print(full_subtypes)

subtypes_list = wz_full['subtype'].unique()
print(subtypes_list)

```

We can see that all four types (ACCIDENT, HAZARD, JAM, ROAD_CLOSED) have the NA subtype. We can also see that the HAZARD type has enough similar subtypes to consider the possibility of sub-subtypes (e.g. HAZARD_ON_ROAD_CAR_STOPPED, HAZARD_ON_ROAD_CONSTRUCTION, HAZARD_ON_ROAD_EMERGENCY_VEHICLE, etc. could have a HAZARD_ON_ROAD sub-subtype)

Bulleted Hierarchy:
-Accident
    -Major
    -Minor
    -NA (Unclassified)
-Hazard
    -On Road
        -Stopped Car
        -Construction
        -Emergency Vehicle
        -Ice
        -Object
        -Pot Hole
        -Traffic Light Fault
        -Lane Closed
        -Roadkill
    -On Shoulder
        -Stopped Car
        -Animals
        -Missing Sign
    -Weather
        -Floor
        -Fog
        -Heavy Snow
        -Hail
    -NA (Unclassified)
-Jam
    -Standstill Traffic
    -Heavy Traffic
    -Moderate Traffic
    -Light Traffic
    -NA (Unclassified)
-Road Closed
    -Event
    -Construction
    -Hazard
    -NA (Unclassified)

Should we keep the NA subtypes or not?

To answer this let's run a count of NA values by type:
```{python}
na_counts = wz_full.groupby('type')['subtype'].apply(lambda incident_type: incident_type.isna().sum())
print(na_counts)

```
Over 90,000 (12%) of our observations have a NA subtype, which represent a significant slice of our data. We can also see that some accident types are disproportionately affected by NAs more than others; over half of NA values are JAM-type incidents (which makes sense, since heavy, moderate, and light traffic is very subjective). Simply moving NAs could thus potentially introduce bias.

4. 
4a. Define a crosswalk df:
```{python}
col_names = ["type", "subtype", "updated_type", "updated_subtype", "updated_subsubtype"]
crosswalk = pd.DataFrame(columns=col_names)

```

4b. Fill in the crosswalk with all unique combinations of type/subtype, then fill in updated_type, updated_subtype, and updated_subsubtype accordingly

(We can do this using drop_duplicates)
```{python}

wz_full = wz_full.fillna("Unclassified")

unique_combinations = wz_full[['type', 'subtype']].drop_duplicates()
crosswalk[['type', 'subtype']] = unique_combinations.reset_index(drop=True)

#We can create a mapping function to copy over the types into updated_type using a dictionary:

def modify_type(value):
    replacements = {
    "JAM": "Jam",
    "ACCIDENT": "Accident",
    "ROAD_CLOSED": "Road Closed",
    "HAZARD": "Hazard"
    }
    return replacements.get(value)

def modify_subtype(value):
    if "HAZARD_ON_ROAD" in value:
        return "Hazard - Road"
    elif "HAZARD_ON_SHOULDER" in value:
        return "Hazard - Shoulder"
    elif "HAZARD_ON_WEATHER" in value:
        return "Hazard - Weather"
    else:
        return value

def modify_subsubtype(value):
    replacements = {
    "Unclassified": "Unclassified",
    "ACCIDENT_MAJOR": "Major Accident",
    "ACCIDENT_MINOR": "Minor Accident",   
    "HAZARD_ON_ROAD": "Road Hazard",
    "HAZARD_ON_ROAD_CAR_STOPPED": "Stopped Car (Road)",
    "HAZARD_ON_ROAD_CONSTRUCTION": "Construction",
    "HAZARD_ON_ROAD_EMERGENCY_VEHICLE": "Emergency Vehicle",
    "HAZARD_ON_ROAD_ICE": "Ice",
    "HAZARD_ON_ROAD_OBJECT": "Object on Road",
    "HAZARD_ON_ROAD_POT_HOLE": "Pot Hole",
    "HAZARD_ON_ROAD_TRAFFIC_LIGHT_FAULT": "Traffic Light Fault",
    "HAZARD_ON_ROAD_LANE_CLOSED": "Lane Closure",
    "HAZARD_ON_ROAD_ROAD_KILL": "Roadkill",
    "HAZARD_ON_SHOULDER": "Shoulder Hazard",
    "HAZARD_ON_SHOULDER_CAR_STOPPED": "Stopped Car (Shoulder)",
    "HAZARD_ON_SHOULDER_ANIMALS": "Animals",
    "HAZARD_ON_SHOULDER_MISSING_SIGN": "Missing Sign",
    "HAZARD_WEATHER": "Weather",
    "HAZARD_WEATHER_FLOOD": "Flood",
    "HAZARD_WEATHER_HAIL": "Hail",
    "HAZARD_WEATHER_FOG": "Fog",
    "HAZARD_WEATHER_HEAVY_SNOW": "Heavy Snow",
    "JAM_HEAVY_TRAFFIC": "Heavy Traffic",
    "JAM_MODERATE_TRAFFIC": "Moderate Traffic",
    "JAM_STAND_STILL_TRAFFIC": "Standstill Traffic",
    "JAM_LIGHT_TRAFFIC": "Light Traffic",
    "ROAD_CLOSED_EVENT": "Event",
    "ROAD_CLOSED_HAZARD": "Hazard",
    "ROAD_CLOSED_CONSTRUCTION": "Construction",
    }
    return replacements.get(value)

crosswalk['updated_type'] = crosswalk['type'].apply(modify_type)
crosswalk['updated_subtype'] = crosswalk['subtype'].apply(modify_subtype)
crosswalk['updated_subsubtype'] = crosswalk['subtype'].apply(modify_subsubtype)

#This code will clean up the lingering old variable names in updated_subtype 

def transpose_subtype(subtype, subsubtype):
    if "_" in subtype:
        return subsubtype
    else:
        return subtype

crosswalk['updated_subtype'] = crosswalk.apply(lambda row: transpose_subtype(row['updated_subtype'], row['updated_subsubtype']), axis=1)

#This code removes duplicate subsubtypes where they're not needed or where subsubtypes don't exist bc a subtype is sufficient
def remove_subsubtypes(subtype, subsubtype):
    if subtype == subsubtype:
        return "Unclassified"
    else:
        return subsubtype

crosswalk['updated_subsubtype'] = crosswalk.apply(lambda row: remove_subsubtypes(row['updated_subtype'], row['updated_subsubtype']), axis=1)

```
4c. Merge the crosswalk with the original data set on type and subtype. How many rows are there for Accident - Unclassified?

1. 
```{python}
print(crosswalk.columns)
print(wz_full.columns)

wz_merge = pd.merge(crosswalk, wz_full, on=['type', 'subtype'], how='inner')

wz_filter = wz_merge[(wz_merge["updated_type"]  == "Accident") & (wz_merge["updated_subtype"] == "Unclassified")]

print(f"There are {len(wz_filter)} rows for Accident - Unclassified type incidents.")


```
Extra Credit: 
```{python}
#Extra credit: Use drop_duplicates() to find the same combinations of values in type and subtype for crosswalk and the merged dataset

print(crosswalk[['updated_type', 'updated_subtype']].drop_duplicates())
print(wz_merge[['updated_type', 'updated_subtype']].drop_duplicates())



```

2. 

```{python}

```

3. 

```{python}

```

4. 

```{python}

```


# App #1: Top Location by Alert Type Dashboard (30 points){-}

1. 

a. 
```{python}

```

b. 
```{python}

```


c. 
```{python}

```

d. 
```{python}

```

3. 
    
a. 

```{python}

```
    

b. 
```{python}
# MODIFY ACCORDINGLY
file_path = "./top_alerts_map/chicago-boundaries.geojson"
#----

with open(file_path) as f:
    chicago_geojson = json.load(f)

geo_data = alt.Data(values=chicago_geojson["features"])

```

4. 

```{python}

```

5. 

a. 

```{python}

```

b. 
```{python}

```

c. 
```{python}

```

d. 
```{python}

```

e. 

# App #2: Top Location by Alert Type and Hour Dashboard (20 points) {-}

1. 

a. 


    
b. 
```{python}

```

c.

```{python}

```
    

2.

a. 



b. 


c. 


# App #3: Top Location by Alert Type and Hour Dashboard (20 points){-}

1. 


a. 

b. 

```{python}

```

2. 

a. 


b. 
    
3. 

a. 
    

b. 


c. 


d.
